{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set names to the paths because they're too long\n",
    "data_path = 'D:\\\\Subjects_In_University\\\\Machine_Learning\\\\data\\\\KNN_Multinomial_Logistic_Regression'\n",
    "# train path\n",
    "train_images_path = os.path.join(data_path, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_path, 'train-labels-idx1-ubyte.gz')\n",
    "# test path\n",
    "test_images_path = os.path.join(data_path, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_path, 't10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(images_path, labels_path, num_images, shuffle=False, _is=True, image_size=28):\n",
    "    \"\"\"\n",
    "    This shuffle param is active when .gz is downloaded at:\n",
    "    - 'http://yann.lecun.com/exdb/mnist/'\n",
    "    - This function return random num_images in 60000 or 10000\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    import gzip # to decompress gz (zip) file\n",
    "    \n",
    "    # open file training to read training data\n",
    "    f_images = gzip.open(images_path,'r')\n",
    "    \n",
    "    # skip 16 first bytes because these are not data, only header infor\n",
    "    f_images.read(16)\n",
    "    \n",
    "    # general: read num_images data samples if this parameter is set;\n",
    "    # if not, read all (60000 training or 10000 test)\n",
    "    \n",
    "    real_num = num_images if not shuffle else (60000 if _is else 10000)\n",
    "    \n",
    "    # read all data to buf_images (28x28xreal_num)\n",
    "    buf_images = f_images.read(image_size * image_size * real_num)\n",
    "    \n",
    "    # images\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(real_num, image_size, image_size,)\n",
    "    \n",
    "    # Read labels\n",
    "    f_labels = gzip.open(labels_path,'r')\n",
    "    f_labels.read(8)\n",
    "    \n",
    "    labels = np.zeros((real_num)).astype(np.int64)\n",
    "    \n",
    "    # rearrange to correspond the images and labels\n",
    "    for i in range(0, real_num):\n",
    "        buf_labels = f_labels.read(1)\n",
    "        labels[i] = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int64)\n",
    "    \n",
    "    # shuffle to get random images data\n",
    "    if shuffle is True:\n",
    "        rand_id = np.random.randint(real_num, size=num_images)\n",
    "    \n",
    "        images = images[rand_id, :]\n",
    "        labels = labels[rand_id,]\n",
    "    \n",
    "    # change images data to type of vector 28x28 dimentional\n",
    "    images = images.reshape(num_images, image_size * image_size)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784) (5000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = get_mnist_data(\n",
    "    train_images_path, train_labels_path, 5000, shuffle=True)\n",
    "\n",
    "test_images, test_labels = get_mnist_data(\n",
    "    test_images_path, test_labels_path, 10000, _is=False, shuffle=True)\n",
    "\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = pd.DataFrame(train_images)\n",
    "train_labels = pd.DataFrame(train_labels)\n",
    "test_images = pd.DataFrame(test_images)\n",
    "test_labels = pd.DataFrame(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 784)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([train_images, test_images], axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat([train_labels, test_labels], axis=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 785)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X, y], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
       "4544  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3477  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1219  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5157  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9031  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      778  779  780  781  782  783  0    \n",
       "4544  0.0  0.0  0.0  0.0  0.0  0.0    2  \n",
       "3477  0.0  0.0  0.0  0.0  0.0  0.0    8  \n",
       "1219  0.0  0.0  0.0  0.0  0.0  0.0    9  \n",
       "5157  0.0  0.0  0.0  0.0  0.0  0.0    3  \n",
       "9031  0.0  0.0  0.0  0.0  0.0  0.0    9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5000 = df.sample(5000, random_state=18)\n",
    "df_5000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df_5000.iloc[:, :-1]\n",
    "y_1 = df_5000.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1.shape, y_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression with original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.8107 s\n",
      "Accuracy: 0.8966666666666666\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size=0.3, random_state=18)\n",
    "\n",
    "logR = LogisticRegression(multi_class='multinomial', solver='sag')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logR.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time: {elapsed_time:.4f} s\")\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression with PCA dataset\n",
    "\n",
    "**Reduce dimension of data then divide to train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.6308 s\n",
      "Accuracy: 0.8793333333333333\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=100)\n",
    "\n",
    "X_pca_divide = pca.fit_transform(X_1)\n",
    "\n",
    "X_pca_divide_train, X_pca_divide_test, y_pca_divide_train, y_pca_divide_test = train_test_split(X_pca_divide, y_1, test_size=0.3, random_state=18)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logR.fit(X_pca_divide_train, y_pca_divide_train)\n",
    "\n",
    "y_pca_divide_pred = logR.predict(X_pca_divide_test)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time: {elapsed_time:.4f} s\")\n",
    "print('Accuracy:', accuracy_score(y_pca_divide_test, y_pca_divide_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Divide to train and test then reduce dimension of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.6273 s\n",
      "Accuracy: 0.31\n"
     ]
    }
   ],
   "source": [
    "X_divide_pca_train = pca.fit_transform(X_train)\n",
    "X_divide_pca_test = pca.fit_transform(X_test)\n",
    "\n",
    "start_time = time.time()\n",
    "logR.fit(X_divide_pca_train, y_train)\n",
    "\n",
    "y_divide_pca_pred = logR.predict(X_divide_pca_test)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time: {elapsed_time:.4f} s\")\n",
    "print('Accuracy:', accuracy_score(y_test, y_divide_pca_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "\n",
    "* Chạy với dữ liệu nguyên bản thì độ chính xác là cao nhất nhưng sẽ tốn nhiều thời gian hơn\n",
    "* Chạy với dữ liệu giảm chiều sau đó chia train test thì độ chính xác giảm đi một chút nhưng thời gian chạy giảm đi rất nhiều so với dữ liệu nguyên bản\n",
    "* Chạy với dữ liệu chia train test sau đó giảm chiều thì độ chính xác rất thấp, thời gian chạy thì cũng khá nhanh\n",
    "\n",
    "**=> Chọn phương pháp: Giảm chiều dữ liệu sau đó chia train test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
