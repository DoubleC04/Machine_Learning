{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e98e7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8727354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:\\\\Subjects_In_University\\\\Machine_Learning\\\\data\\\\KNN_Multinomial_Logistic_Regression'\n",
    "train_images_path = os.path.join(data_path, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_path, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_path = os.path.join(data_path, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_path, 't10k-labels-idx1-ubyte.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43b269fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(images_path, labels_path, num_images, shuffle=False, _is=True, image_size=28):\n",
    "    f_images = gzip.open(images_path, 'r')\n",
    "    f_images.read(16)\n",
    "    real_num = num_images if not shuffle else (60000 if _is else 10000)\n",
    "    buf_images = f_images.read(image_size * image_size * real_num)\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(real_num, image_size, image_size)\n",
    "    \n",
    "    f_labels = gzip.open(labels_path, 'r')\n",
    "    f_labels.read(8)\n",
    "    labels = np.zeros((real_num)).astype(np.int64)\n",
    "    for i in range(0, real_num):\n",
    "        buf_labels = f_labels.read(1)\n",
    "        labels[i] = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int64)\n",
    "    \n",
    "    if shuffle:\n",
    "        rand_id = np.random.randint(real_num, size=num_images)\n",
    "        images = images[rand_id, :]\n",
    "        labels = labels[rand_id]\n",
    "    \n",
    "    images = images.reshape(num_images, image_size * image_size)\n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4c55204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập huấn luyện: (5000, 784) (5000,)\n",
      "Kích thước tập kiểm tra: (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = get_mnist_data(train_images_path, train_labels_path, 5000, shuffle=True)\n",
    "test_images, test_labels = get_mnist_data(test_images_path, test_labels_path, 10000, _is=False, shuffle=True)\n",
    "print(\"Kích thước tập huấn luyện:\", train_images.shape, train_labels.shape)\n",
    "print(\"Kích thước tập kiểm tra:\", test_images.shape, test_labels.shape)\n",
    "\n",
    "train_images = train_images / 255.0  \n",
    "test_images = test_images / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b28508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 784  \n",
    "C = 10  \n",
    "reg = 0.05  \n",
    "lr = 0.1    \n",
    "batch_size = 100\n",
    "num_iters = 1000\n",
    "\n",
    "W = np.random.randn(d, C) * 0.01 \n",
    "\n",
    "def svm_loss_vectorized(W, X, y, reg):\n",
    "    d, C = W.shape\n",
    "    _, N = X.shape\n",
    "    Z = W.T.dot(X) \n",
    "    correct_class_score = np.choose(y, Z).reshape(N, 1).T  \n",
    "    margins = np.maximum(0, Z - correct_class_score + 1)  \n",
    "    margins[y, np.arange(margins.shape[1])] = 0  \n",
    "    \n",
    "    loss = np.sum(margins, axis=(0, 1)) / N\n",
    "    loss += 0.5 * reg * np.sum(W * W)\n",
    "    \n",
    "    F = (margins > 0).astype(int)\n",
    "    F[y, np.arange(F.shape[1])] = np.sum(-F, axis=0)\n",
    "    dW = X.dot(F.T) / N + reg * W\n",
    "    return loss, dW\n",
    "\n",
    "def multiclass_svm_GD_vectorized(X, y, Winit, reg, lr=0.1, batch_size=100, num_iters=1000, print_every=100):\n",
    "    W = Winit\n",
    "    loss_history = np.zeros((num_iters))\n",
    "    for it in range(num_iters):\n",
    "        idx = np.random.choice(X.shape[1], batch_size)\n",
    "        X_batch = X[:, idx]\n",
    "        y_batch = y[idx]\n",
    "        loss_history[it], dW = svm_loss_vectorized(W, X_batch, y_batch, reg)\n",
    "        W -= lr * dW\n",
    "        if it % print_every == 1:\n",
    "            print(f'it {it}/{num_iters}, loss = {loss_history[it]:.4f}')\n",
    "    return W, loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "992a2a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 1/1000, loss = 6.1755\n",
      "it 101/1000, loss = 0.7758\n",
      "it 201/1000, loss = 0.8348\n",
      "it 301/1000, loss = 0.8619\n",
      "it 401/1000, loss = 0.9526\n",
      "it 501/1000, loss = 0.8438\n",
      "it 601/1000, loss = 0.6020\n",
      "it 701/1000, loss = 0.9166\n",
      "it 801/1000, loss = 0.7235\n",
      "it 901/1000, loss = 0.8784\n",
      "Độ chính xác trên tập kiểm tra: 0.8761\n",
      "Ma trận nhầm lẫn:\n",
      " [[ 844    0    7   32    0   30   22    0    2    0]\n",
      " [   0 1088    4   10    0    2    4    0   25    0]\n",
      " [   7    3  860   59   14    4   12   14   56    6]\n",
      " [   0    0   20  976    2   26    2    1   19   12]\n",
      " [   0    4   15    3  875    0   14    1   21  111]\n",
      " [   4    3    9   83   10  714   12    3   42   13]\n",
      " [   5    3   19    6   29    3  830    1    3    0]\n",
      " [   1   14   52   12    6    5    1  849   23   86]\n",
      " [   7    2   10   50    6   29    4    3  823   28]\n",
      " [   8    6    5   18   30    9    2    5    5  902]]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_images.T  \n",
    "y_train = train_labels    \n",
    "W_opt, loss_history = multiclass_svm_GD_vectorized(X_train, y_train, W, reg, lr, batch_size, num_iters, print_every=100)\n",
    "\n",
    "X_test = test_images.T  \n",
    "y_test = test_labels   \n",
    "Z_test = W_opt.T.dot(X_test) \n",
    "y_pred = np.argmax(Z_test, axis=0) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Độ chính xác trên tập kiểm tra: {accuracy:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Ma trận nhầm lẫn:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e39663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
