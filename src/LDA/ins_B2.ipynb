{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đường dẫn dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set names to the paths because they're too long\n",
    "data_path = 'D:\\\\Subjects_In_University\\\\Machine_Learning\\\\data\\\\KNN_Multinomial_Logistic_Regression'\n",
    "# train path\n",
    "train_images_path = os.path.join(data_path, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_path, 'train-labels-idx1-ubyte.gz')\n",
    "# test path\n",
    "test_images_path = os.path.join(data_path, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_path, 't10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm giải nén dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(images_path, labels_path, num_images, shuffle=False, _is=True, image_size=28):\n",
    "    \"\"\"\n",
    "    This shuffle param is active when .gz is downloaded at:\n",
    "    - 'http://yann.lecun.com/exdb/mnist/'\n",
    "    - This function return random num_images in 60000 or 10000\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    import gzip # to decompress gz (zip) file\n",
    "    \n",
    "    # open file training to read training data\n",
    "    f_images = gzip.open(images_path,'r')\n",
    "    \n",
    "    # skip 16 first bytes because these are not data, only header infor\n",
    "    f_images.read(16)\n",
    "    \n",
    "    # general: read num_images data samples if this parameter is set;\n",
    "    # if not, read all (60000 training or 10000 test)\n",
    "    \n",
    "    real_num = num_images if not shuffle else (60000 if _is else 10000)\n",
    "    \n",
    "    # read all data to buf_images (28x28xreal_num)\n",
    "    buf_images = f_images.read(image_size * image_size * real_num)\n",
    "    \n",
    "    # images\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(real_num, image_size, image_size,)\n",
    "    \n",
    "    # Read labels\n",
    "    f_labels = gzip.open(labels_path,'r')\n",
    "    f_labels.read(8)\n",
    "    \n",
    "    labels = np.zeros((real_num)).astype(np.int64)\n",
    "    \n",
    "    # rearrange to correspond the images and labels\n",
    "    for i in range(0, real_num):\n",
    "        buf_labels = f_labels.read(1)\n",
    "        labels[i] = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int64)\n",
    "    \n",
    "    # shuffle to get random images data\n",
    "    if shuffle is True:\n",
    "        rand_id = np.random.randint(real_num, size=num_images)\n",
    "    \n",
    "        images = images[rand_id, :]\n",
    "        labels = labels[rand_id,]\n",
    "    \n",
    "    # change images data to type of vector 28x28 dimentional\n",
    "    images = images.reshape(num_images, image_size * image_size)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lấy ra tập train và tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784) (5000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = get_mnist_data(\n",
    "    train_images_path, train_labels_path, 5000, shuffle=True)\n",
    "\n",
    "test_images, test_labels = get_mnist_data(\n",
    "    test_images_path, test_labels_path, 10000, _is=False, shuffle=True)\n",
    "\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuyển tập train và tập test thành một DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.DataFrame(train_images)\n",
    "train_labels = pd.DataFrame(train_labels)\n",
    "test_images = pd.DataFrame(test_images)\n",
    "test_labels = pd.DataFrame(test_labels)\n",
    "\n",
    "X = pd.concat([train_images, test_images], axis=0)\n",
    "y = pd.concat([train_labels, test_labels], axis=0)\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df_5000 = df.sample(5000, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5000 = df_5000.iloc[:, :-1]\n",
    "y_5000 = df_5000.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khởi tạo `PCA` giảm chiều dữ liệu về 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "\n",
    "X_pca = pca.fit_transform(X_5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khởi tạo mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logR = LogisticRegression(multi_class='multinomial', solver='sag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng phương pháp Multinomial Logistic Regression để phân loại. \n",
    "\n",
    "Tỷ lệ train:test là 0.7:0.3.\n",
    "\n",
    "So sánh độ chính xác và thời gian chạy mô hình trong các trường hợp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dữ liệu nguyên bản**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8926666666666667\n",
      "Run time: 4.6331627368927\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_5000, y_5000, test_size=0.3, random_state=18)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logR.fit(X_train, y_train)\n",
    "y_pred = logR.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Run time:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dữ liệu đã PCA về 100 chiều**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.884\n",
      "Run time: 0.5869491100311279\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_5000, test_size=0.3, random_state=18)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logR.fit(X_train, y_train)\n",
    "y_pred = logR.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Run time:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dữ liệu đã LDA về 8 chiều**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.932\n",
      "Run time: 0.06802797317504883\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=8)\n",
    "\n",
    "X_lda = lda.fit_transform(X_5000, y_5000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda, y_5000, test_size=0.3, random_state=18)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logR.fit(X_train, y_train)\n",
    "y_pred = logR.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Run time:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Từ kết quả chạy ta thấy dữ liệu sau khi giảm chiều bằng phương pháp LDA xong chia dữ liệu cho độ chính xác cao hơn so với sử dụng phương pháp PCA và dữ liệu ban đầu. \n",
    "\n",
    "=> Nên phương pháp LDA là phù hợp nhất."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
